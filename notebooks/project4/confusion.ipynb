{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.data.project4.dataloader import get_loaders \n",
    "from src.models.project4.models import get_model\n",
    "from src.utils import set_seed, get_optimizer\n",
    "from src.models.project4.losses import get_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = OmegaConf.create({\n",
    "    'model_name': 'resnet18',\n",
    "    'region_size': 224,\n",
    "    'batch_size': 1,\n",
    "    'optimizer': 'Adam',\n",
    "    'loss': 'CrossEntropy',\n",
    "    'data_path': '/work3/s194253/02514/project4_results/data_wastedetection',\n",
    "    'use_super_categories': True,\n",
    "    'lr': 1e-04,\n",
    "    'out': False,\n",
    "    'seed': 0,\n",
    "    'verbose': False,\n",
    "    'percentage_to_freeze': None,\n",
    "})\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Get data loaders with applied transformations\n",
    "loaders, num_classes = get_loaders(\n",
    "    dataset='waste', \n",
    "    batch_size=args.batch_size, \n",
    "    seed=args.seed, \n",
    "    num_workers=1,\n",
    "    img_size = (512, 512),\n",
    "    region_size = (args.region_size, args.region_size),\n",
    "    use_super_categories=args.use_super_categories,\n",
    "    root = args.data_path,\n",
    ")\n",
    "\n",
    "id2cat = loaders['train'].dataset.id2cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = get_loss(args.loss)\n",
    "optimizer = get_optimizer(args.optimizer)\n",
    "\n",
    "model = get_model(args.model_name, args, loss_fun, optimizer, out=args.out, num_classes=num_classes, region_size=(args.region_size, args.region_size), id2cat=loaders['train'].dataset.id2cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded!\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = '/work3/s194253/02514/project4_results/logs/albertkjoller_efficientnet_crossentropy_resnet/resnet18/albertkjoller_efficientnet_crossentropy_resnet/resnet18/'\n",
    "\n",
    "\n",
    "VERSION = 0\n",
    "EPOCH_NAME = 'epoch=6_loss_val=0.3089.ckpt'\n",
    "\n",
    "checkpoint_path = BASE_PATH + f'version_{VERSION}/checkpoints/' + EPOCH_NAME\n",
    "\n",
    "model = model.load_from_checkpoint(checkpoint_path, loss_fun=loss_fun)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(\"Checkpoint loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import plot_SS\n",
    "from torchvision.ops import box_iou, nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_cat: tensor([28, 28, 28, 28,  1, 28, 28, 28, 28, 25, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "        28, 28,  1, 28, 28, 28, 28, 28, 28,  1, 28, 28, 28, 28, 28, 28,  1, 19,\n",
      "        28,  0, 28, 28,  1, 28, 28, 28, 28, 28, 19, 28, 19, 28, 28, 28, 28, 28,\n",
      "        28, 28, 28, 28, 28, 28,  1, 26, 19, 28, 28, 28,  1,  1, 28, 28, 28, 28,\n",
      "        28, 28, 28, 28, 28,  0, 28, 28, 28, 28, 28, 28, 28,  1, 28, 28, 28,  1,\n",
      "        28, 28, 28, 28, 28,  1, 28, 28,  1, 28, 19, 28, 19, 28, 28, 28, 28, 28,\n",
      "        28, 28, 28, 28, 19, 28, 28,  0,  1, 28, 28, 28, 28,  1, 28,  1, 28, 28,\n",
      "        28,  0, 28, 28, 28, 28, 28, 28, 28, 28,  1,  1, 28,  1, 28, 28, 28, 28,\n",
      "        28, 28, 19, 28, 28,  0, 28, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "batch_idx = 1\n",
    "batch = loaders['test'].dataset.__getitem__(batch_idx)\n",
    "\n",
    "# for each image\n",
    "i = 0\n",
    "(img, cat_ids, bboxes_data, pred_bboxes_data) = batch\n",
    "\n",
    "# for each bounding box\n",
    "(bboxes, regions)           = bboxes_data # - not available at this point\n",
    "(pred_bboxes, pred_regions) = pred_bboxes_data\n",
    "\n",
    "# Classify proposed regions\n",
    "y_hat = model.forward(pred_regions.to(device))\n",
    "\n",
    "# maximum probabilities\n",
    "outputs = torch.nn.functional.softmax(y_hat, dim=1)\n",
    "pred_prob, pred_cat = torch.max(outputs, 1)\n",
    "\n",
    "print(\"pred_cat:\", pred_cat)\n",
    "\n",
    "# Applying NMS (remove redundant boxes)\n",
    "keep_indices = nms(pred_bboxes.to(torch.float).to(device), pred_prob, 0.5).cpu()\n",
    "\n",
    "# Computing AP\n",
    "preds = {'boxes': pred_bboxes.cpu()[keep_indices][pred_cat.cpu()[keep_indices] != max(model.id2cat.keys())], \n",
    "        'scores': pred_prob.cpu()[keep_indices][pred_cat.cpu()[keep_indices]   != max(model.id2cat.keys())], \n",
    "        'labels': pred_cat.cpu()[keep_indices][pred_cat.cpu()[keep_indices]    != max(model.id2cat.keys())]} \n",
    "\n",
    "targets = {\n",
    "    'boxes':  bboxes, \n",
    "    'labels': cat_ids.flatten()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1, 19,  1, 25, 26,  1,  1,  1, 19, 19])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_SS(\n",
    "    img, \n",
    "    targets['boxes'].detach().cpu(), \n",
    "    targets['labels'].detach().cpu(), \n",
    "    preds['boxes'].detach().cpu(), \n",
    "    preds['labels'].detach().cpu(), \n",
    "    preds['scores'].detach().cpu(),\n",
    "    i,\n",
    "    batch_idx,\n",
    "    id2cat,\n",
    "    path = './'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_matches, gt_matches, box_labels, gt2pred = model.compare_boxes(bboxes, cat_ids, pred_bboxes, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [71] at index 0 does not match the shape of the indexed tensor [12] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds[\u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m][box_labels[keep_indices] \u001b[39m!=\u001b[39;49m \u001b[39m28\u001b[39;49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [71] at index 0 does not match the shape of the indexed tensor [12] at index 0"
     ]
    }
   ],
   "source": [
    "preds['labels'][box_labels[keep_indices] != 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 12]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# plt.savefig(f'{folder_path}/idx{idx}.png', dpi=300, bbox_inches='tight')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     disp\u001b[39m.\u001b[39mplot(xticks_rotation\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m conf_mat(preds[\u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m], targets[\u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m], id2cat, \u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m, in \u001b[0;36mconf_mat\u001b[0;34m(preds, targets, classes, idx)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconf_mat\u001b[39m(preds, targets, classes, idx):\n\u001b[1;32m      2\u001b[0m     fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m     cm \u001b[39m=\u001b[39m confusion_matrix(targets, preds, labels\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(classes\u001b[39m.\u001b[39;49mkeys()))\n\u001b[1;32m      4\u001b[0m     disp \u001b[39m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[39m=\u001b[39mcm,\n\u001b[1;32m      5\u001b[0m                                 display_labels\u001b[39m=\u001b[39mclasses\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m      6\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/work3/s184984/02514/project4_results/predict_imgs\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/DLinCV/DLCV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[1;32m    233\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    319\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/DLinCV/DLCV/lib/python3.11/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/DLinCV/DLCV/lib/python3.11/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 12]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def conf_mat(preds, targets, classes, idx):\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "    cm = confusion_matrix(targets, preds, labels=list(classes.keys()))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                display_labels=classes.values())\n",
    "    path = '/work3/s184984/02514/project4_results/predict_imgs'\n",
    "    # disp.ax_.rotate_yticklabels(20)\n",
    "    folder_path = f\"{path}/{path.split('/')[-1]}_batchidx{batch_idx}\"\n",
    "    # plt.savefig(f'{folder_path}/idx{idx}.png', dpi=300, bbox_inches='tight')\n",
    "    disp.plot(xticks_rotation=0.2)\n",
    "\n",
    "conf_mat(preds['labels'], targets['labels'], id2cat, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(img.permute(1,2,0))\n",
    "for i, bbox in enumerate(preds['boxes'][preds['labels'] != 28]):\n",
    "    rect = patches.Rectangle(\n",
    "        (bbox[0].item(), bbox[1].item()), \n",
    "        width=(bbox[2] - bbox[0]).item(), \n",
    "        height=(bbox[3] - bbox[1]).item(), \n",
    "        linewidth=2, \n",
    "        edgecolor=f\"r\", \n",
    "        facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "for i, bbox in enumerate(targets['boxes']):\n",
    "    rect = patches.Rectangle(\n",
    "        (bbox[0].item(), bbox[1].item()), \n",
    "        width=(bbox[2] - bbox[0]).item(), \n",
    "        height=(bbox[3] - bbox[1]).item(), \n",
    "        linewidth=2, \n",
    "        edgecolor=f\"b\", \n",
    "        facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "plt.show()\n",
    "plt.close()\n",
    "fig.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/work3/s194253/02514/project4_results/logs/albertkjoller_efficientnet/efficientnet_b4/albertkjoller_efficientnet/efficientnet_b4/version_2/checkpoints/epoch=28_val_loss=0.0000.ckpt'\n",
    "\n",
    "model.load_from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
