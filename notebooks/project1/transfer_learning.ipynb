{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint \n",
    "\n",
    "from src.data.project1.dataloader import get_loaders, get_normalization_constants\n",
    "from src.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "accuracy = BinaryAccuracy().to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing mean of training split...: 100%|█| 1638/1638 [00:04<00:00, 330.43\n",
      "Computing std. dev. of training split...: 100%|█| 1638/1638 [00:06<00:00, 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean: tensor([0.5132, 0.4369, 0.3576])\n",
      "Std. dev.: tensor([0.0214, 0.0208, 0.0223])\n"
     ]
    }
   ],
   "source": [
    "ROOT = '/dtu/datasets1/02514/hotdog_nothotdog'\n",
    "SEED = 0\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Get normalization constants\n",
    "train_mean, train_std = get_normalization_constants(root=ROOT, seed=SEED)\n",
    "\n",
    "# Define transforms for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),         # flips \"left-right\"\n",
    "    # transforms.RandomVerticalFlip(p=1.0),           # flips \"upside-down\"\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.RandomRotation(degrees=(60, 70)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=train_mean, \n",
    "        std=train_std, \n",
    "    )\n",
    "])\n",
    "\n",
    "# Define transforms for test and validation\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=train_mean, \n",
    "        std=train_std, \n",
    "    )\n",
    "])\n",
    "\n",
    "# Get data loaders with applied transformations\n",
    "loaders = get_loaders(\n",
    "    root=ROOT, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    seed=SEED, \n",
    "    train_transforms=train_transforms, \n",
    "    test_transforms=test_transforms, \n",
    "    num_workers=24\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get example batch\n",
    "batch, targets = next(iter(loaders['train'])) \n",
    "out = model(batch)\n",
    "torch.argmax(nn.functional.softmax(out, dim=1), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.functional.one_hot(targets, num_classes=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-class (Lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning model\n",
    "class HotdogEfficientNet(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load model\n",
    "        self.efficient_net = timm.create_model('efficientnet_b4', pretrained=True, num_classes=2)\n",
    "        # Freeze weights\n",
    "        for param in self.efficient_net.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Require gradient for classification layer\n",
    "        self.efficient_net.classifier.requires_grad_()\n",
    "\n",
    "\n",
    "        # Define metrics and loss criterion\n",
    "        self.criterion = nn.BCEWithLogitsLoss() # nn.BCELoss()\n",
    "        self.accuracy = BinaryAccuracy().to(self.device)\n",
    "\n",
    "        # Set up logging option\n",
    "        self.model_checkpoint = ModelCheckpoint(\n",
    "            monitor = \"val_loss\",\n",
    "            verbose=True,\n",
    "            filename=\"{epoch}_{val_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.efficient_net(x) # out # torch.argmax(nn.functional.softmax(out, dim=1), dim = 1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 1e-4)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Extract and process input\n",
    "        x, y = batch\n",
    "        y = torch.nn.functional.one_hot(y, num_classes=2) \n",
    "        y = y.to(torch.float32)\n",
    "\n",
    "        # Get prediction, loss and accuracy\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "\n",
    "        # logs metrics for each training_step - [default:True],\n",
    "        # the average across the epoch, to the progress bar and logger-[default:False]\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True),\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Extract and process input\n",
    "        x, y = batch\n",
    "        x, y = x.to(self.device), y.to(self.device)\n",
    "        y = torch.nn.functional.one_hot(y, num_classes=2) \n",
    "        y = y.to(torch.float32) \n",
    "\n",
    "        # Get prediction, loss and accuracy\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "\n",
    "        # logs metrics for each validation_step - [default:False]\n",
    "        #the average across the epoch - [default:True]\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True),\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# dm = HotDogDataModule()\n",
    "HotdogModel = HotdogEfficientNet()\n",
    "\n",
    "#CPU:default,GPU:gpus,TPU:tpu_cores\n",
    "trainer = pl.Trainer(\n",
    "    devices=1, \n",
    "    accelerator=\"gpu\", \n",
    "    max_epochs = 10,\n",
    "    log_every_n_steps=2,\n",
    "    callbacks=[HotdogModel.model_checkpoint]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | efficient_net | EfficientNet      | 17.6 M\n",
      "1 | criterion     | BCEWithLogitsLoss | 0     \n",
      "2 | accuracy      | BinaryAccuracy    | 0     \n",
      "----------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "17.5 M    Non-trainable params\n",
      "17.6 M    Total params\n",
      "70.209    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ba34dcdfb647b3b9fcf9cfdefef81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s194253/02514/DL-COMVIS/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/work3/s194253/02514/DL-COMVIS/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/work3/s194253/02514/DL-COMVIS/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3533946053124f5c9fac67ec67b32c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ca8db4e03e42bca3578183a308fe9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 52: 'val_loss' reached 1.78380 (best 1.78380), saving model to '/work3/s194253/02514/lightning_logs/version_4/checkpoints/epoch=0_val_loss=1.7838.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c321d34e74c0409f850b8181f3718281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 104: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02365633baf452c8982cc87c166150d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 156: 'val_loss' reached 1.73783 (best 1.73783), saving model to '/work3/s194253/02514/lightning_logs/version_4/checkpoints/epoch=2_val_loss=1.7378.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d582c2bca09a484785a11ce3bbff8ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 208: 'val_loss' reached 1.61779 (best 1.61779), saving model to '/work3/s194253/02514/lightning_logs/version_4/checkpoints/epoch=3_val_loss=1.6178.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e217c0037ba74a5bb6849a33c1d02418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 260: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6b86b3f9954dc6af85bb5a4b3ef0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 312: 'val_loss' reached 1.59753 (best 1.59753), saving model to '/work3/s194253/02514/lightning_logs/version_4/checkpoints/epoch=5_val_loss=1.5975.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e944082c0bdc4541be1cf1515f318385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 364: 'val_loss' reached 1.52202 (best 1.52202), saving model to '/work3/s194253/02514/lightning_logs/version_4/checkpoints/epoch=6_val_loss=1.5220.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1458195b161941e4ae22eaca0f6b96f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 416: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956a2d9ae9014d07bf4b5dc992ba1d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 468: 'val_loss' reached 1.47394 (best 1.47394), saving model to '/work3/s194253/02514/lightning_logs/version_4/checkpoints/epoch=8_val_loss=1.4739.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece7408d0e934ef8a261ed06ec6cecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 520: 'val_loss' reached 1.43407 (best 1.43407), saving model to '/work3/s194253/02514/lightning_logs/version_4/checkpoints/epoch=9_val_loss=1.4341.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=HotdogModel,\n",
    "    train_dataloaders = loaders['train'],\n",
    "    val_dataloaders = loaders['validation'], \n",
    ") \n",
    "\n",
    "#manually you can save best checkpoints - \n",
    "trainer.save_checkpoint(\"DL-COMVIS/models/modelshotdog_efficient_net.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
